# Pose_Interactions_UseTech

## Описание задачи

Разработка системы анализа видео с камер наблюдения, которая:
- обнаруживает людей на каждом кадре видеопотока,
- отслеживает их перемещение по кадрам с помощью трекинга,
- определяет позы людей,
- определяет взаимодействие между людьми 

## Структура проекта
```
project/
├── main.py                  # Главный файл запуска пайплайна
├── detector.py              # Обнаружение людей
├── pose_estimator.py        # Детекция ключевых точек
├── tracker_module.py        # Трекинг людей
├── draw_utils.py            # Отрисовка keypoints и skeleton
├── behavior_analyzer.py     # Логика анализа позы (пока отсутствует)
├── config.py                # Конфигурационные параметры
├── track_data.json          # Итоговый JSON-файл с данными
└── requirements.txt         # Зависимости
```

## Установка и запуск

1. Установите зависимости:

```bash
pip install -r requirements.txt
```
(рекомендую ставить `torch` вручную для правильной версии CUDA)

2. Подготовьте входные файлы

- `Test_video.mp4` — видео для обработки
- `yolo12x.pt` — обученная модель YOLO12
- `yolo11x-pose.pt` — обученная модель YOLO11 Pose

3. Запуск

```bash
python main.py
```

## Пайплайн обработки видео

### 1. Загрузка и инициализация (`config.py`)

- Загрузка входного видео `Test_video.mp4` с помощью OpenCV (`cv2.VideoCapture`)
- Получение:
  - размеров кадра (`width`, `height`)
  - частоты кадров (`fps`)
- Подготовка объекта записи для выходного видео `output_analysis.mp4`
- Задание конфигураций:
  - `conf_threshold = 0.3` — порог уверенности YOLO-детектора
  - `keypoint_threshpoint = 0.3` — минимальная уверенность ключевой точки
  (даннные конфигурации не рекомендуется поднимать из-за низкого качество видео на камерах видеонаблюдения)

### 2. Детекция людей на кадре (`detector.py`)

- Загружает модель `yolo12x.pt`
- Функция `detect_people(frame)`:
  - принимает кадр
  - возвращает bounding boxes для объектов класса `"person"`

### 3. Трекинг объектов (`tracker_module.py`)

- Создаёт экземпляр трекера `DeepSort`
- Функция `update_tracks(detections, frame)`:
  - принимает bbox’ы и кадр
  - возвращает список активных треков с `track_id`
 
### 4. Вырезка ROI и определение поз (`pose_estimator.py`)

- Загружает модель `yolo11x-pose.pt`
- Функция `get_pose_from_roi(roi)`:
  - принимает вырезанную область (ROI)
  - возвращает список из 17 ключевых точек (`keypoints`)
- Фильтрует точки по уверенности

### 5. Օтрисовка позы и скелета (`draw_utils.py`)
- Определяет связи между keypoints (скелет)
- Функция `draw_skeleton(frame, keypoints, offset_x, offset_y)`:
  - рисует точки и линии на кадре
  - Красные точки — keypoints
  - Синие линии — кости/связи
 
### 6. Сбор всех модулей (`main.py`)
- **Инициализация**:
  - Открывает видео (`cv2.VideoCapture`)
  - Извлекает параметры: ширину, высоту, fps
  - Создаёт объект `cv2.VideoWriter` для сохранения выходного видео

-  **Цикл обработки кадров**:
  - Считывает кадр
  - Вызывает:
    - `detect_people()` для получения bbox людей
    - `update_tracks()` для отслеживания ID
    - `get_pose_from_roi()` для извлечения ключевых точек
    - `analyze_behavior()` для определения позы
    - `draw_skeleton()` и отрисовку bbox и ID

-  **Формирует JSON-структуру**:
  - Для каждого кадра:
    - сохраняет `timestamp` (время кадра в секундах)
    - собирает список всех отслеживаемых людей с их:
      - ID
      - координатами bbox
      - keypoints (17 штук)
      - поведением (`flags`)
  - Данные аккумулируются в словарь `track_data`


    Пример структуры JSON:
    
    ```json
    {
      "frame_00025": {
        "timestamp": 1.05,
        "people": [
          {
            "id": 3,
            "bbox": [340, 150, 420, 360],
            "keypoints": [
              [351, 160], ..., [400, 144]
            ],
            "flags": {
              "sitting": false,
              "gesturing": true
            }
          }
        ]
      }
    }
    ```
- **Сохраняет результаты**:
  - Кадр записывается в выходное видео с аннотациями
  - После завершения:
    - выходное видео сохраняется (`output_analysis.mp4`)
    - JSON-файл записывается на диск (`track_data.json`)

## Используемые технологии
- OpenCV  
- PyTorch  
- YOLOv8 (детектор) + YOLOv8-Pose (позы)  
- DeepSORT (через `deep_sort_realtime`)  
- JSON, NumPy

## Используемые технологии
  **Гарник Матевосян**  
  Факультет прикладной математики и информатики  
  2025
  
